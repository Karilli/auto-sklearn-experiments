{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    import sys\n",
    "    # make sure that you import the correct version of auto-sklearn\n",
    "    # that supports Resamplers\n",
    "    sys.path.insert(0, \"../my_autosklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create My_SVMSMOTE for balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConfigSpace.configuration_space import ConfigurationSpace\n",
    "from autosklearn.pipeline.components.base import AutoSklearnPreprocessingAlgorithm\n",
    "from autosklearn.pipeline.constants import DENSE, INPUT, SIGNED_DATA, SPARSE, UNSIGNED_DATA\n",
    "from ConfigSpace.hyperparameters import UniformIntegerHyperparameter, CategoricalHyperparameter, UniformFloatHyperparameter\n",
    "\n",
    "\n",
    "class My_SVMSMOTE(AutoSklearnPreprocessingAlgorithm):\n",
    "    def __init__(self, k_neighbors=5, sampling_strategy=\"minority\", C=1.0, random_state=None):\n",
    "        self.random_state = random_state\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        self.C = C\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "        from imblearn.over_sampling import SVMSMOTE\n",
    "        from sklearn.svm import SVC\n",
    "        return SVMSMOTE(\n",
    "            k_neighbors=self.k_neighbors, \n",
    "            sampling_strategy=self.sampling_strategy,\n",
    "            svm_estimator=SVC(\n",
    "                C=self.C,\n",
    "            ),\n",
    "        ).fit_resample(X, y)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_properties(dataset_properties=None):\n",
    "        return {\n",
    "            \"shortname\": \"SVMSMOTE\",\n",
    "            \"name\": \"SVMSMOTE\",\n",
    "            \"handles_regression\": False,\n",
    "            \"handles_classification\": True,\n",
    "            \"handles_multiclass\": False,\n",
    "            \"handles_multilabel\": False,\n",
    "            \"handles_multioutput\": False,\n",
    "            \"is_deterministic\": True,\n",
    "            \"input\": (SPARSE, DENSE, UNSIGNED_DATA, SIGNED_DATA),\n",
    "            \"output\": (INPUT,),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_hyperparameter_search_space(feat_type=None, dataset_properties=None):\n",
    "        cs = ConfigurationSpace()\n",
    "        # NOTE: This is just to showcase possibilities of ConfigSpace\n",
    "        cs.add_hyperparameters([\n",
    "            UniformIntegerHyperparameter(name=\"k_neighbors\", lower=3, upper=10, default_value=5, log=False),\n",
    "            CategoricalHyperparameter(name=\"sampling_strategy\", choices=[\"all\", \"not minority\", \"not majority\", \"minority\"], default_value=\"minority\"),\n",
    "            UniformFloatHyperparameter(name=\"C\", lower=0.03125, upper=32768, default_value=1.0, log=True),\n",
    "        ])\n",
    "        return cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add My_SVMSMOTE to auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.pipeline.components.data_preprocessing.balancing\n",
    "autosklearn.pipeline.components.data_preprocessing.balancing.add_preprocessor(My_SVMSMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create LOF for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConfigSpace.configuration_space import ConfigurationSpace\n",
    "from autosklearn.pipeline.components.base import AutoSklearnPreprocessingAlgorithm\n",
    "from autosklearn.pipeline.constants import DENSE, INPUT, SIGNED_DATA, SPARSE, UNSIGNED_DATA\n",
    "from ConfigSpace.hyperparameters import UniformFloatHyperparameter\n",
    "\n",
    "\n",
    "class My_LOF(AutoSklearnPreprocessingAlgorithm):\n",
    "    def __init__(self, p=0.01, random_state=None):\n",
    "        self.random_state = random_state\n",
    "        self.p = p\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "        from sklearn.neighbors import LocalOutlierFactor\n",
    "        import numpy as np\n",
    "\n",
    "        clf = LocalOutlierFactor()\n",
    "        clf.fit_predict(X)\n",
    "        factors = clf.negative_outlier_factor_\n",
    "        inliers = np.argsort(-factors)[:int((1-self.p) * len(factors))]\n",
    "        return X[inliers], y[inliers]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_properties(dataset_properties=None):\n",
    "        return {\n",
    "            \"shortname\": \"LOF\",\n",
    "            \"name\": \"LOF\",\n",
    "            \"handles_regression\": True,\n",
    "            \"handles_classification\": True,\n",
    "            \"handles_multiclass\": True,\n",
    "            \"handles_multilabel\": False,\n",
    "            \"handles_multioutput\": False,\n",
    "            \"is_deterministic\": True,\n",
    "            \"input\": (SPARSE, DENSE, UNSIGNED_DATA, SIGNED_DATA),\n",
    "            \"output\": (INPUT,),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_hyperparameter_search_space(feat_type=None, dataset_properties=None):\n",
    "        cs = ConfigurationSpace()\n",
    "        # parameter that controls percentage of instances to remove\n",
    "        cs.add_hyperparameters([\n",
    "            UniformFloatHyperparameter(name=\"p\", lower=0.0, upper=0.1, default_value=0.01, log=False)\n",
    "        ])\n",
    "        return cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create AutoSklearnChoice for encapsulating more anomaly detection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConfigSpace.configuration_space import ConfigurationSpace\n",
    "from autosklearn.pipeline.components.base import AutoSklearnChoice\n",
    "from collections import OrderedDict\n",
    "from ConfigSpace.hyperparameters import CategoricalHyperparameter\n",
    "\n",
    "\n",
    "# You can also customize methods:\n",
    "# - get_available_components\n",
    "# - set_hyperparameters\n",
    "# But it is unlikely that you would need to.\n",
    "class My_AnomalyDetectionChoice(AutoSklearnChoice):\n",
    "    def __init__(self, feat_type, dataset_properties, random_state=None):\n",
    "        self.random_state = random_state\n",
    "\n",
    "    @classmethod\n",
    "    def get_components(cls):\n",
    "        return OrderedDict([(\"My_LOF\", My_LOF)])\n",
    "\n",
    "    def get_hyperparameter_search_space(self, feat_type, dataset_properties=None, default=None, include=None, exclude=None):\n",
    "        if dataset_properties is None:\n",
    "            dataset_properties = {}\n",
    "\n",
    "        available_components = self.get_available_components(dataset_properties=dataset_properties, include=include, exclude=exclude)\n",
    "\n",
    "        choice = CategoricalHyperparameter(\"__choice__\", list(available_components.keys()), default_value=\"My_LOF\")\n",
    "        cs = ConfigurationSpace()\n",
    "        cs.add_hyperparameter(choice)\n",
    "\n",
    "        for name, preprocessor in available_components.items():\n",
    "            space = preprocessor.get_hyperparameter_search_space(dataset_properties=dataset_properties)\n",
    "            cs.add_configuration_space(name, space, parent_hyperparameter={\"parent\": choice, \"value\": name})\n",
    "        return cs\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "        return self.choice.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add My_AnomalyDetectionChoice to classification pipeline of auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this cell multiple times\n",
    "if \"STEP_ADDED\" not in locals():\n",
    "    from autosklearn.pipeline.classification import SimpleClassificationPipeline\n",
    "\n",
    "    old_pipeline_steps = SimpleClassificationPipeline._get_pipeline_steps\n",
    "    def _get_pipeline_steps(self, dataset_properties, feat_type=None):\n",
    "        default_dataset_properties = {\"target_type\": \"classification\"}\n",
    "        if dataset_properties is not None and isinstance(dataset_properties, dict):\n",
    "            default_dataset_properties.update(dataset_properties)\n",
    "\n",
    "        steps = old_pipeline_steps(self, dataset_properties, feat_type)\n",
    "        choice = My_AnomalyDetectionChoice(feat_type=feat_type, dataset_properties=default_dataset_properties, random_state=self.random_state)\n",
    "        steps.insert(1, (\"my_anomaly_detection\", choice))\n",
    "        return steps\n",
    "\n",
    "    SimpleClassificationPipeline._get_pipeline_steps = _get_pipeline_steps\n",
    "    STEP_ADDED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting to the training data: 100%|\u001b[32m██████████\u001b[0m| 30/30 [00:21<00:00,  1.41it/s, The total time budget for this task is 0:00:30]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2: {'model_id': 2,\n",
       "  'rank': 2,\n",
       "  'cost': 0.04255319148936165,\n",
       "  'ensemble_weight': 0.04,\n",
       "  'data_preprocessor': FeatTypeSplit(numerical_transformer:imputation:strategy: mean,\n",
       "  \t\tnumerical_transformer:rescaling:__choice__: standardize,),\n",
       "  'my_anomaly_detection': My_LOF(random_state=1),\n",
       "  'balancing': My_SVMSMOTE(random_state=1),\n",
       "  'feature_preprocessor': NoPreprocessing(random_state=None),\n",
       "  'classifier': RandomForest(bootstrap=True, criterion='gini', max_depth=None, max_features=0.5,\n",
       "               max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "               min_samples_split=2, min_weight_fraction_leaf=0.0, random_state=1),\n",
       "  'sklearn_classifier': RandomForestClassifier(max_features=5, n_estimators=512, n_jobs=1,\n",
       "                         random_state=1, warm_start=True)},\n",
       " 3: {'model_id': 3,\n",
       "  'rank': 3,\n",
       "  'cost': 0.04255319148936165,\n",
       "  'ensemble_weight': 0.32,\n",
       "  'data_preprocessor': FeatTypeSplit(numerical_transformer:imputation:strategy: median,\n",
       "  \t\tnumerical_transformer:rescaling:__choice__: power_transformer,),\n",
       "  'my_anomaly_detection': My_LOF(p=0.058341527212025096, random_state=1),\n",
       "  'balancing': My_SVMSMOTE(C=0.4746206067036156, k_neighbors=10, random_state=1,\n",
       "              sampling_strategy='not minority'),\n",
       "  'feature_preprocessor': LibLinear_Preprocessor(C=0.15856993338516046, dual=False, fit_intercept=True,\n",
       "                         intercept_scaling=1.0, loss='squared_hinge',\n",
       "                         multi_class='ovr', penalty='l1', random_state=1,\n",
       "                         tol=0.0012000058187373434),\n",
       "  'classifier': LDA(shrinkage='auto', tol=0.01433792514307336),\n",
       "  'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
       "                             tol=0.01433792514307336)},\n",
       " 4: {'model_id': 4,\n",
       "  'rank': 1,\n",
       "  'cost': 0.02659574468085102,\n",
       "  'ensemble_weight': 0.54,\n",
       "  'data_preprocessor': FeatTypeSplit(numerical_transformer:imputation:strategy: median,\n",
       "  \t\tnumerical_transformer:rescaling:__choice__: power_transformer,),\n",
       "  'my_anomaly_detection': My_LOF(p=0.006078817706958817, random_state=1),\n",
       "  'balancing': My_SVMSMOTE(C=0.468087837089311, k_neighbors=8, random_state=1,\n",
       "              sampling_strategy='not minority'),\n",
       "  'feature_preprocessor': SelectPercentileClassification(percentile=49, random_state=1,\n",
       "                                 score_func=functools.partial(<function mutual_info_classif at 0x7f38dad92440>, random_state=1)),\n",
       "  'classifier': PassiveAggressive(C=0.002562742313896232, average=False, fit_intercept=True,\n",
       "                    loss='squared_hinge', random_state=1,\n",
       "                    tol=2.259348694683648e-05),\n",
       "  'sklearn_classifier': PassiveAggressiveClassifier(C=0.002562742313896232, loss='squared_hinge',\n",
       "                              max_iter=128, random_state=1,\n",
       "                              tol=2.259348694683648e-05, warm_start=True)},\n",
       " 5: {'model_id': 5,\n",
       "  'rank': 4,\n",
       "  'cost': 0.1436170212765957,\n",
       "  'ensemble_weight': 0.1,\n",
       "  'data_preprocessor': FeatTypeSplit(numerical_transformer:imputation:strategy: median,\n",
       "  \t\tnumerical_transformer:rescaling:__choice__: none,),\n",
       "  'my_anomaly_detection': My_LOF(p=0.018251670766405527, random_state=1),\n",
       "  'balancing': My_SVMSMOTE(C=0.04181764348742392, k_neighbors=4, random_state=1,\n",
       "              sampling_strategy='not majority'),\n",
       "  'feature_preprocessor': PCA(keep_variance=0.8591843587290433, random_state=1, whiten=False),\n",
       "  'classifier': AdaboostClassifier(algorithm='SAMME.R', learning_rate=0.057327468673852175,\n",
       "                     max_depth=2, n_estimators=66, random_state=1),\n",
       "  'sklearn_classifier': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
       "                     learning_rate=0.057327468673852175, n_estimators=66,\n",
       "                     random_state=1)}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "model = AutoSklearnClassifier(\n",
    "    include = {\n",
    "        \"balancing\": [\"My_SVMSMOTE\"],  # restrict balancing to only My_SVMSMOTE\n",
    "    },\n",
    "    tmp_folder=\"temp/anomaly\",\n",
    "    initial_configurations_via_metalearning=0,\n",
    "    time_left_for_this_task=30,\n",
    "    per_run_time_limit=10,\n",
    ")\n",
    "model.fit(X, y)\n",
    "model.show_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
