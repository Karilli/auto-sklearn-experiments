{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_datasets\n",
    "from experiments import get_experiments\n",
    "from file_loader import Folders, load_json, load_pkl, dump_pkl, dump_json\n",
    "from metrics import (\n",
    "    imbalance_ratio,\n",
    "    partial_roc_auc_score_,\n",
    "    harmonic_mean_recall_,\n",
    "    NEW_ASKL_METRICS\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from pprint import pprint\n",
    "from os.path import exists\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    recall_score, \n",
    "    precision_score, \n",
    "    f1_score,\n",
    "    fbeta_score, \n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIT=0\n",
    "VALIDATE=1\n",
    "RUN_INFO=0\n",
    "IGNORE_ERRORS=0\n",
    "\n",
    "TIME = 8 * 60\n",
    "TIME_PER_RUN = 90\n",
    "K_FOLDS = 5\n",
    "N_JOBS = 15\n",
    "SEED = 0\n",
    "REMOVE_TEMP = False\n",
    "MEM = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_info(model, dataset_name, ratio, experiment_name, run_info_file):\n",
    "    print(f\"Computing run summary, {dataset_name}, {ratio:.2f}, {experiment_name} ...\")\n",
    "    os.makedirs(os.path.dirname(run_info_file), exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        ensemble = model.show_models()\n",
    "    except:\n",
    "        ensemble = None\n",
    "\n",
    "    with open(run_info_file, 'w') as f:\n",
    "        f.write(model.sprint_statistics())\n",
    "        f.write(\"\\n\")\n",
    "        pprint(model.leaderboard(), stream=f)\n",
    "        f.write(\"\\n\")\n",
    "        pprint(ensemble, stream=f)\n",
    "        f.write(\"\\n\")\n",
    "        dct = defaultdict(Counter)\n",
    "        for key, val in model.automl_.runhistory_.data.items():\n",
    "            status = str(val.status).split(\".\")[1]\n",
    "            balancing = model.automl_.runhistory_.ids_config[key.config_id]['balancing:strategy']\n",
    "            dct[balancing][status] += 1\n",
    "        pprint(dct, stream=f)\n",
    "        f.write(\"\\n\")\n",
    "        if ensemble is None:\n",
    "            return\n",
    "\n",
    "        ensemble = [(model, str(model[\"balancing\"]).split(\"(\")[0]) for model in ensemble.values()]\n",
    "        dct = {\n",
    "            \"statuses\": Counter(str(val.status) for val in model.automl_.runhistory_.data.values()),\n",
    "            \"none\": sum(model[\"ensemble_weight\"] for model, balancing_name in ensemble if balancing_name == \"NoPreprocessing\"), \n",
    "            \"weighting\": sum(model[\"ensemble_weight\"] for model, balancing_name in ensemble if balancing_name == \"Weighting\"), \n",
    "            \"smote\": sum(model[\"ensemble_weight\"] for model, balancing_name in ensemble if balancing_name not in (\"NoPreprocessing\", \"Weighting\")), \n",
    "            \"smote_sampling_strategy\": [\n",
    "                (model[\"balancing\"].choice.sampling_strategy, model[\"ensemble_weight\"])\n",
    "                for model, balancing_name in ensemble if balancing_name not in (\"NoPreprocessing\", \"Weighting\")\n",
    "            ],\n",
    "            \"ensemble_size\": len(ensemble)\n",
    "        }\n",
    "        pprint(dct, stream=f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_settings(model, experiment, X, y):\n",
    "    if experiment[\"CLASSIFIER\"] != \"auto-sklearn\":\n",
    "        return\n",
    "\n",
    "    default = model.get_configuration_space(X, y)[\"balancing:strategy\"].default_value\n",
    "    choices = model.get_configuration_space(X, y)[\"balancing:strategy\"].choices\n",
    "    sampling_startegy = \"balancing:SVMSMOTE:sampling_strategy\" in model.get_configuration_space(X, y)\n",
    "    expected_default = experiment[\"DEFAULT\"]\n",
    "    expected_choices = sorted(experiment[\"INCLUDE\"][\"balancing\"])\n",
    "\n",
    "    metric = Counter(str(m) for m in model.metric)\n",
    "    expected_metric = Counter(str(m) for m in experiment[\"METRIC\"])\n",
    "\n",
    "    assert model.time_left_for_this_task == TIME, model.time_left_for_this_task\n",
    "    assert model.per_run_time_limit == TIME_PER_RUN\n",
    "    assert model.seed == SEED\n",
    "    assert model.memory_limit == MEM\n",
    "    assert model.n_jobs == N_JOBS, model.n_jobs\n",
    "    assert model.resampling_strategy.n_splits == K_FOLDS\n",
    "    assert model.resampling_strategy.shuffle == True\n",
    "    assert model.resampling_strategy.random_state == SEED\n",
    "\n",
    "    assert metric == expected_metric, f\"Expected {expected_metric}, but got {metric}\"\n",
    "    assert model.initial_configurations_via_metalearning == experiment[\"META\"]\n",
    "\n",
    "    assert default == expected_default, f\"expected:{expected_default}, but got: {default}\"\n",
    "    assert sorted(choices) == expected_choices, f\"expected:{expected_choices}, but got: {choices}\"\n",
    "    if \"SAMPLING_STRATEGY\" in experiment:\n",
    "        assert sampling_startegy == experiment[\"SAMPLING_STRATEGY\"], f\"Expected {experiment['SAMPLING_STRATEGY']}, but got {sampling_startegy}\"\n",
    "    else:\n",
    "        assert not sampling_startegy\n",
    "    # data_prep_choices = model.get_configuration_space(X, y)[\"data_preprocessor:__choice__\"].choices\n",
    "    # assert list(data_prep_choices) == [\"feature_type\"], list(data_prep_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(skf, model, X, y, scores, validation_file, dataset_name, ratio, experiment_name):\n",
    "    def help(y_test, y_pred, postfix):\n",
    "        return {\n",
    "            f\"confusion_matrix_{postfix}\": [int(val) for val in confusion_matrix(y_test, y_pred).ravel()],\n",
    "\n",
    "            f\"minority_precision_{postfix}\": precision_score(y_test, y_pred, pos_label=1, average='binary', zero_division=0.0),\n",
    "            f\"majority_precision_{postfix}\": precision_score(y_test, y_pred, pos_label=0, average='binary', zero_division=0.0),\n",
    "            f\"weighted_precision_{postfix}\": precision_score(y_test, y_pred, average='weighted', zero_division=0.0),\n",
    "            f\"macro_precision_{postfix}\": precision_score(y_test, y_pred, average='macro', zero_division=0.0),\n",
    "            \n",
    "            f\"minority_recall_{postfix}\": recall_score(y_test, y_pred, pos_label=1, average='binary', zero_division=0.0),\n",
    "            f\"majority_recall_{postfix}\": recall_score(y_test, y_pred, pos_label=0, average='binary', zero_division=0.0),\n",
    "            f\"weighted_recall_{postfix}\": recall_score(y_test, y_pred, average='weighted', zero_division=0.0),\n",
    "            f\"macro_recall_{postfix}\": recall_score(y_test, y_pred, average='macro', zero_division=0.0),\n",
    "            \n",
    "            f\"minority_f1_{postfix}\": f1_score(y_test, y_pred, pos_label=1, average='binary', zero_division=0.0),\n",
    "            f\"majority_f1_{postfix}\": f1_score(y_test, y_pred, pos_label=0, average='binary', zero_division=0.0),\n",
    "            f\"weighted_f1_{postfix}\": f1_score(y_test, y_pred, average='weighted', zero_division=0.0),\n",
    "            f\"macro_f1_{postfix}\": f1_score(y_test, y_pred, average='macro', zero_division=0.0),\n",
    "            \n",
    "            f\"minority_f2_{postfix}\": fbeta_score(y_test, y_pred, beta=2, pos_label=1, average='binary', zero_division=0.0),\n",
    "            f\"majority_f2_{postfix}\": fbeta_score(y_test, y_pred, beta=2, pos_label=0, average='binary', zero_division=0.0),\n",
    "            f\"weighted_f2_{postfix}\": fbeta_score(y_test, y_pred, beta=2, average='weighted', zero_division=0.0),\n",
    "            f\"macro_f2_{postfix}\": fbeta_score(y_test, y_pred, beta=2, average='macro', zero_division=0.0),\n",
    "\n",
    "            f\"weighted_harmonic_mean_recall_{postfix}\": harmonic_mean_recall_(y_test, y_pred, weight=1),\n",
    "            f\"weighted_harmonic_mean_recall_2_{postfix}\": harmonic_mean_recall_(y_test, y_pred, weight=2),\n",
    "        }\n",
    "\n",
    "    print(f\"Validating, {dataset_name}, {ratio:.2f}, {experiment_name} ...\", end=\" \", flush=True)\n",
    "    IR = imbalance_ratio(y, mode=\"big\")\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        fold = str(fold)\n",
    "        print(fold, end=\" \", flush=True)\n",
    "\n",
    "        if fold in scores and isinstance(scores[fold], dict) and all(metric in scores[fold] for metric in (\"y_prob\", \"y_test\")):\n",
    "            y_prob = scores[fold][\"y_prob\"]\n",
    "            y_test = scores[fold][\"y_test\"]\n",
    "        else:\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            if hasattr(model, \"refit\"):\n",
    "                model = model.refit(X_train, y_train)\n",
    "            else:\n",
    "                if model.steps[0][0] == \"weighting\":\n",
    "                    unique, counts = np.unique(y_train, return_counts=True)\n",
    "                    cw = 1 / (counts / np.sum(counts)) / 2\n",
    "                    sample_weight = np.ones(y_train.shape)\n",
    "                    for i, ue in enumerate(unique):\n",
    "                        sample_weight[y_train == ue] *= cw[i]\n",
    "                    model = model.fit(X_train, y_train, RF__sample_weight=sample_weight)\n",
    "                else:\n",
    "                    model = model.fit(X_train, y_train)\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        scores[fold] = {\n",
    "            \"auc_roc\": roc_auc_score(y_test, y_prob),\n",
    "            \"pr_auc_roc\": partial_roc_auc_score_(y_test, y_prob),\n",
    "            \"y_prob\": [float(y) for y in y_prob],\n",
    "            \"y_test\": [float(y) for y in y_test],\n",
    "        }\n",
    "\n",
    "        scores[fold] |= help(y_test, [0.5 <= p for p in y_prob], \"default\")\n",
    "\n",
    "        y_threshold, y_test, y_prob_threshold, y_prob = train_test_split(y_test, y_prob, test_size=0.5, stratify=y_test, random_state=SEED, shuffle=True)\n",
    "        fpr, tpr, thresholds = roc_curve(y_threshold, y_prob_threshold)\n",
    "        scores[fold] |= help(y_test, thresholds[np.argmax(3*tpr*(1-fpr)/(tpr+2*(1-fpr)))] <= y_prob, \"weighted_harmonic_mean\")\n",
    "\n",
    "        scores[fold] |= help(y_test, thresholds[np.argmax(tpr - fpr / IR)] <= y_prob, \"tpr-fpr/IR\")\n",
    "        for k in [0.05, 0.067, 0.1, 0.2, 0.5, 0.75, 0.9, 1]:\n",
    "            scores[fold] |= help(y_test, thresholds[np.argmax(tpr - k * fpr)] <= y_prob, f\"tpr-{k}*fpr\")\n",
    "\n",
    "    dump_json(scores, validation_file)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    import sys\n",
    "    sys.path.insert(0, \"../my_autosklearn\")\n",
    "    from autosklearn.classification import AutoSklearnClassifier\n",
    "\n",
    "    import autosklearn.pipeline.components.data_preprocessing\n",
    "    from no_data_preprocessor import NoPreprocessing\n",
    "    autosklearn.pipeline.components.data_preprocessing.add_preprocessor(NoPreprocessing)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class IdentityTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X\n",
    "\n",
    "\n",
    "MODEL_DICT = {\n",
    "    \"weighting\": IdentityTransformer(),\n",
    "    \"SVMSMOTE\": SVMSMOTE(random_state=SEED),\n",
    "    \"RF\": RandomForestClassifier(random_state=SEED)\n",
    "}\n",
    "\n",
    "\n",
    "def stop_after_100_configurations_callback(smbo, run_info, result, time_left):\n",
    "    return sum(\"SUCCESS\" in str(val.status) for val in smbo.runhistory.data.values()) <= 116\n",
    "\n",
    "\n",
    "def get_model(dataset_name, X, y, ratio, experiment_name, experiment, model_file, temp, skf):\n",
    "    if exists(model_file):\n",
    "        print(f\"Loading, {dataset_name}, {ratio:.2f}, {experiment_name} ...\")\n",
    "        return load_pkl(model_file)\n",
    "\n",
    "    if experiment[\"CLASSIFIER\"] == \"auto-sklearn\":\n",
    "        print(f\"Fitting, {dataset_name}, {ratio:.2f}, {experiment_name} ...\")\n",
    "\n",
    "        if exists(temp):\n",
    "            shutil.rmtree(temp, ignore_errors=True)\n",
    "\n",
    "        model = AutoSklearnClassifier(\n",
    "            time_left_for_this_task=TIME,\n",
    "            metric=[NEW_ASKL_METRICS[metric] for metric in experiment[\"METRIC\"]],\n",
    "            initial_configurations_via_metalearning=experiment[\"META\"],\n",
    "            include=experiment[\"INCLUDE\"],\n",
    "            resampling_strategy=skf,\n",
    "            seed=SEED,\n",
    "            tmp_folder=temp,\n",
    "            delete_tmp_folder_after_terminate=REMOVE_TEMP,\n",
    "            get_trials_callback=stop_after_100_configurations_callback if \"CALLBACK\" in experiment and experiment[\"CALLBACK\"] else None,\n",
    "            n_jobs=N_JOBS,\n",
    "            memory_limit=MEM,\n",
    "            per_run_time_limit=TIME_PER_RUN\n",
    "        )\n",
    "        check_model_settings(model, experiment, X, y)\n",
    "        model = model.fit(X, y)\n",
    "        dump_pkl(model, model_file)\n",
    "        return model\n",
    "\n",
    "    return Pipeline([\n",
    "        (primitive, MODEL_DICT[primitive])\n",
    "        for primitive in experiment[\"CLASSIFIER\"].split(\"+\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_id, dataset_name, X, y, ratio, experiment_name, experiment):\n",
    "    file_destination = f\"{experiment_name}/{dataset_name}/{ratio:.2f}\"\n",
    "    validation_file = f\"{Folders.VALIDATION_DIR}/{file_destination}.json\"\n",
    "    model_file = f\"{Folders.MODELS_DIR}/{file_destination}.pkl\"\n",
    "    run_info_file = f\"{Folders.RUN_INFO_DIR}/{file_destination}.txt\"\n",
    "    temp = f\"{Folders.TEMP}/{run_id}\"\n",
    "    scores = load_json(validation_file)\n",
    "    skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    if not exists(model_file) and not FIT and experiment[\"CLASSIFIER\"] == \"auto-sklearn\":\n",
    "        return\n",
    "    model = get_model(dataset_name, X, y, ratio, experiment_name, experiment, model_file, temp, skf)\n",
    "    check_model_settings(model, experiment, X, y)\n",
    "    if RUN_INFO and experiment[\"CLASSIFIER\"] == \"auto-sklearn\":\n",
    "        run_info(model, dataset_name, ratio, experiment_name, run_info_file)\n",
    "    if VALIDATE:\n",
    "        validate(skf, model, X, y, scores, validation_file, dataset_name, ratio, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading, diabetes(id=37), 0.54, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ...\n",
      "Validating, diabetes(id=37), 0.54, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ... 0 1 2 3 4 \n",
      "Loading, diabetes(id=37), 0.15, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ...\n",
      "Validating, diabetes(id=37), 0.15, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ... 0 1 2 3 4 \n",
      "Loading, diabetes(id=37), 0.10, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ...\n",
      "Validating, diabetes(id=37), 0.10, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ... 0 1 2 3 4 \n",
      "Loading, diabetes(id=37), 0.05, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ...\n",
      "Validating, diabetes(id=37), 0.05, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ... 0 1 2 3 4 \n",
      "Loading, pc3(id=1050), 0.11, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ...\n",
      "Validating, pc3(id=1050), 0.11, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ... 0 1 2 3 4 \n",
      "Loading, pc3(id=1050), 0.10, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ...\n",
      "Validating, pc3(id=1050), 0.10, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ... 0 1 2 3 4 \n",
      "Loading, pc3(id=1050), 0.05, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ...\n",
      "Validating, pc3(id=1050), 0.05, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ... 0 1 2 3 4 \n",
      "Loading, JM1(id=1053), 0.24, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ...\n",
      "Validating, JM1(id=1053), 0.24, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ... 0 1 2 3 4 \n",
      "Loading, JM1(id=1053), 0.15, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ...\n",
      "Validating, JM1(id=1053), 0.15, all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25 ... 0 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_id, dataset_name, X, y, ratio, experiment_name, experiment)\u001b[0m\n\u001b[1;32m     15\u001b[0m     run_info(model, dataset_name, ratio, experiment_name, run_info_file)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m VALIDATE:\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 44\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(skf, model, X, y, scores, validation_file, dataset_name, ratio, experiment_name)\u001b[0m\n\u001b[1;32m     42\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighting\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/auto-sklearn/my_code/../my_autosklearn/autosklearn/estimators.py:799\u001b[0m, in \u001b[0;36mAutoSklearnEstimator.refit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrefit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    775\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Refit all models found with fit to new data.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \n\u001b[1;32m    777\u001b[0m \u001b[38;5;124;03m    Necessary when using cross-validation. During training, auto-sklearn\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    797\u001b[0m \n\u001b[1;32m    798\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoml_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/auto-sklearn/my_code/../my_autosklearn/autosklearn/automl.py:1206\u001b[0m, in \u001b[0;36mAutoML.refit\u001b[0;34m(self, X, y, max_reshuffles)\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_budget_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1206\u001b[0m         \u001b[43m_fit_and_suppress_warnings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1208\u001b[0m         _fit_with_budget(\n\u001b[1;32m   1209\u001b[0m             X_train\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   1210\u001b[0m             Y_train\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task,\n\u001b[1;32m   1217\u001b[0m         )\n",
      "File \u001b[0;32m~/auto-sklearn/my_code/../my_autosklearn/autosklearn/evaluation/abstract_evaluator.py:189\u001b[0m, in \u001b[0;36m_fit_and_suppress_warnings\u001b[0;34m(logger, model, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    188\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mshowwarning \u001b[38;5;241m=\u001b[39m send_warnings_to_log\n\u001b[0;32m--> 189\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/auto-sklearn/my_code/../my_autosklearn/autosklearn/pipeline/base.py:128\u001b[0m, in \u001b[0;36mBasePipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     X \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/auto-sklearn/my_code/../my_autosklearn/autosklearn/pipeline/base.py:146\u001b[0m, in \u001b[0;36mBasePipeline.fit_estimator\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_estimator\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m    143\u001b[0m     fit_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    144\u001b[0m         key\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m): value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m fit_params\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    145\u001b[0m     }\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/auto-sklearn/my_code/../my_autosklearn/autosklearn/pipeline/components/base.py:473\u001b[0m, in \u001b[0;36mAutoSklearnChoice.fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/auto-sklearn/my_code/../my_autosklearn/autosklearn/pipeline/components/base.py:201\u001b[0m, in \u001b[0;36mIterativeComponentWithSampleWeight.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration_fully_fitted():\n\u001b[1;32m    200\u001b[0m     n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39miteration \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterative_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/auto-sklearn/my_code/../my_autosklearn/autosklearn/pipeline/components/classification/extra_trees.py:126\u001b[0m, in \u001b[0;36mExtraTreesClassifier.iterative_fit\u001b[0;34m(self, X, y, sample_weight, n_iter, refit)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mn_estimators \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m n_iter\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mn_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:190\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    188\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:295\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    293\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(y\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_):\n\u001b[0;32m--> 295\u001b[0m     classes_k, y_encoded[:, k] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mappend(classes_k)\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\u001b[38;5;241m.\u001b[39mappend(classes_k\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/auto-sklearn/.venv/lib/python3.10/site-packages/numpy/lib/arraysetops.py:341\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n\u001b[1;32m    339\u001b[0m mask[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (equal_nan \u001b[38;5;129;01mand\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfmM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43maux\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# for complex all NaNs are considered equivalent\u001b[39;00m\n\u001b[1;32m    343\u001b[0m         aux_firstnan \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39misnan(aux), \u001b[38;5;28;01mTrue\u001b[39;00m, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" and (VALIDATE or FIT or RUN_INFO):\n",
    "    DATASETS = get_datasets()\n",
    "    EXPERIMENTS = [\n",
    "        # \"SVMSMOTE-default=SVMSMOTE-META=25-metric=[harmonic_mean_recall_2]\",\n",
    "        # \"weighting-default=weighting-META=25-metric=[harmonic_mean_recall_2]\",\n",
    "        # \"none-default=none-META=25-metric=[harmonic_mean_recall_2]\",\n",
    "\n",
    "        # \"RF\",\n",
    "        # \"SVMSMOTE+RF\",\n",
    "        # \"weighting+RF\",\n",
    "\n",
    "        # \"SVMSMOTE-default=SVMSMOTE-META=25-sampling_strategy=False\",\n",
    "        # \"SVMSMOTE-default=SVMSMOTE-META=25\",\n",
    "        # \"weighting-default=weighting-META=25\",\n",
    "        # \"none-default=none-META=25\",\n",
    "\n",
    "        # \"SVMSMOTE-default=SVMSMOTE-META=25-callback\",\n",
    "        # \"weighting-default=weighting-META=25-callback\",\n",
    "        # \"none-default=none-META=25-callback\",\n",
    "\n",
    "        \"all_SMOTE_like+weighting+none-default=SVMSMOTE-META=25\"\n",
    "    ]\n",
    "    assert set(EXPERIMENTS) <= set(get_experiments().keys()), set(EXPERIMENTS) - set(get_experiments().keys())\n",
    "\n",
    "    jobs = [\n",
    "        (dataset_name, X, y, ratio, experiment_name, experiment)\n",
    "        for experiment_name, experiment in get_experiments().items()\n",
    "        for dataset_name, X, y, ratio in DATASETS\n",
    "        if experiment_name in EXPERIMENTS\n",
    "    ]\n",
    "\n",
    "    for i, (dataset_name, X, y, ratio, experiment_name, experiment) in enumerate(jobs):\n",
    "        if IGNORE_ERRORS:\n",
    "            try:\n",
    "                run(i, dataset_name, X, y, ratio, experiment_name, experiment)\n",
    "            except TypeError as e: \n",
    "                if \"is not JSON serializable\" in str(e):\n",
    "                    raise e\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            run(i, dataset_name, X, y, ratio, experiment_name, experiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
